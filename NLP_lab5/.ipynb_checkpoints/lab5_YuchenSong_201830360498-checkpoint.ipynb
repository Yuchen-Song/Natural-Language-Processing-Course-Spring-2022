{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author: Yuchen Song\n",
    "# student_id: 201830360498\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Bidirectional, Input, Dense, Activation, Embedding, Dropout, TimeDistributed, GRU, Add, Lambda\n",
    "from tensorflow.keras.layers import dot, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from data_helper import load_data\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"\" # uncomment this line, if you use cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "dropout_rate = 0.2\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "embedding_dim = 100\n",
    "\n",
    "# gru parameters\n",
    "hidden_dim = 100\n",
    "num_encoder_layer = 2\n",
    "num_decoder_layer = 1\n",
    "\n",
    "# attention parameters\n",
    "# None donates that no self-attenti0n mechanism is used\n",
    "# 'dot' indicated the self-attention mechanism presented in the tutorial\n",
    "attention_type = 'dot'  # [None, 'dot', 'multiplicative', 'additive']\n",
    "\n",
    "\n",
    "def seq2seq_predict(seq2seq_model, encoder_input, decoder_sequence_length, sos_idx):\n",
    "    # because we do not have the truth decoder input,\n",
    "    # we need to use the decoder prediction as its input\n",
    "    decoder_input = np.zeros(\n",
    "        shape=(len(encoder_input), decoder_sequence_length))\n",
    "    decoder_input[:, 0] = sos_idx\n",
    "    for i in range(1, decoder_sequence_length):\n",
    "        output = seq2seq_model.predict(\n",
    "            [encoder_input, decoder_input], batch_size=batch_size).argmax(axis=2)\n",
    "        decoder_input[:, i] = output[:, i-1]\n",
    "    return output\n",
    "\n",
    "\n",
    "def recover_sentence(x, idx2word):\n",
    "    s = []\n",
    "    for idx in x:\n",
    "        word = idx2word[idx]\n",
    "        if word == '<sos>':\n",
    "            continue\n",
    "        elif word == '<eos>':\n",
    "            break\n",
    "        elif word == '<pad>':\n",
    "            break\n",
    "        s.append(word)\n",
    "    return s\n",
    "\n",
    "\n",
    "class TestCallback(Callback):\n",
    "    \"\"\"\n",
    "    Calculate BLEU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, test_data, model, vocabulary):\n",
    "        self.test_data = test_data\n",
    "        self.model = model\n",
    "        self.vocabulary = vocabulary\n",
    "        self.idx2word = dict()\n",
    "        for k, v in self.vocabulary.items():\n",
    "            self.idx2word[v] = k\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        [encoder_input, decoder_input, decoder_target] = self.test_data\n",
    "        decoder_output = seq2seq_predict(\n",
    "            self.model, encoder_input, decoder_input_train.shape[1], vocabulary['<sos>'])\n",
    "        bleu, results = self.evaluate_bleu(decoder_target, decoder_output)\n",
    "        results.sort(reverse=True)\n",
    "        print('Validation Set BLEU: %f' % (bleu))\n",
    "        print('Top | BLEU | %s | %s' %\n",
    "              ('target'.ljust(20), 'output'.ljust(20)))\n",
    "        indices = list(range(len(results)))\n",
    "        candidate_indices = list()\n",
    "        candidate_indices.extend(indices[0:3])\n",
    "        step = len(indices)//10\n",
    "        if step > 0:\n",
    "            candidate_indices.extend(indices[2+step::step])\n",
    "        if indices[-1] != candidate_indices[-1]:\n",
    "            candidate_indices.append(indices[-1])\n",
    "        for i in candidate_indices:\n",
    "            r = results[i]\n",
    "            print('%-4d|%.4f| %s | %s' %\n",
    "                  (i, r[0], ' '.join(r[1]), ' '.join(r[2])))\n",
    "\n",
    "    def evaluate_bleu(self, target, output):\n",
    "        N = target.shape[0]\n",
    "        sum_bleu = 0.0\n",
    "        results = []\n",
    "        for i in range(N):\n",
    "            t = recover_sentence(target[i], self.idx2word)\n",
    "            o = recover_sentence(output[i], self.idx2word)\n",
    "            bleu = nltk.translate.bleu_score.sentence_bleu([t], o)\n",
    "            sum_bleu += bleu\n",
    "            results.append((bleu, t, o))\n",
    "        return sum_bleu / N, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "encoder_input_train.shape (12244, 10)\n",
      "decoder_input_train.shape (12244, 10)\n",
      "Vocab Size 3243\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print('Loading data')\n",
    "    encoder_input_train, decoder_input_train, decoder_target_train, \\\n",
    "        encoder_input_valid, decoder_input_valid, decoder_target_valid, vocabulary = load_data(\n",
    "            'translation')\n",
    "    vocab_size = len(vocabulary)\n",
    "\n",
    "    print('encoder_input_train.shape', encoder_input_train.shape) # （12244，10）\n",
    "    print('decoder_input_train.shape', decoder_input_train.shape) # （12244，10）\n",
    "    print('Vocab Size', vocab_size) # 3243\n",
    "\n",
    "    num_training_data = encoder_input_train.shape[0]\n",
    "    encoder_sequence_length = encoder_input_train.shape[1]\n",
    "    decoder_sequence_length = decoder_input_train.shape[1]\n",
    "\n",
    "    # encoder_input -> [batch_size, encoder_sequence_length]\n",
    "    # decoder_input -> [batch_size, decoder_sequence_length]\n",
    "    encoder_input = Input(shape=(encoder_sequence_length,), dtype='int32')\n",
    "    decoder_input = Input(shape=(decoder_sequence_length,), dtype='int32')\n",
    "\n",
    "    # the encoder and decoder share the same embedding layer\n",
    "    emb_layer = Embedding(input_dim=vocab_size,\n",
    "                          output_dim=embedding_dim, mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "    ################\n",
    "    # ENCODER PART #\n",
    "    ################\n",
    "\n",
    "    # embedding -> [batch_size, sequence_length, embedding_dim]\n",
    "    ### YOUR CODE HERE ###\n",
    "    encoder_input_embed = emb_layer(encoder_input)\n",
    "\n",
    "    # dropout at embedding layer\n",
    "    ### YOUR CODE HERE ###\n",
    "    encoder_input_droped = Dropout(dropout_rate)(encoder_input_embed)\n",
    "\n",
    "    # add multiple Bidirectional GRU layers here,\n",
    "    # set units=hidden_dim, return_sequences=True at the previous layers\n",
    "    # set units=hidden_dim, return_sequences=True, return_state=True at the last layer\n",
    "    # please read https://keras.io/layers/recurrent/\n",
    "    # output:\n",
    "    #     if return_sequences==True:\n",
    "    #         gru_output -> [batch_size, sequence_length, 2*hidden_dim]\n",
    "    #     if return_sequences==True and return_state=True:\n",
    "    #         gru_output -> [batch_size, sequence_length, 2*hidden_dim], [batch_size, hidden_dim], [batch_size, hidden_dim]\n",
    "\n",
    "    encoder_inputs = [encoder_input_droped]\n",
    "    for i in range(0, num_encoder_layer-1):\n",
    "        # N − 1 layer(s) of Bidirectional GRU, which return(s) sequences only, i.e., set return_sequences=True, unroll=True.\n",
    "        ### YOUR CODE HERE ###\n",
    "        encoder_output = Bidirectional(GRU(hidden_dim, return_sequences=True, unroll=True))(encoder_inputs[i])\n",
    "        # Dropout layers between GRU layers if applicable.\n",
    "        ### YOUR CODE HERE ###\n",
    "        encoder_output_droped = Dropout(dropout_rate)(encoder_output)\n",
    "\n",
    "        encoder_inputs.append(encoder_output_droped)\n",
    "    # 1 layer of Bidirectional GRU, which returns sequences and the last state.\n",
    "    encoder_output, encoder_last_h, encoder_last_hr = Bidirectional(GRU(units=hidden_dim,\n",
    "                                                                        return_sequences=True, \n",
    "                                                                        return_state=True, \n",
    "                                                                        unroll=True))(encoder_inputs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ################\n",
    "    # DECODER PART #\n",
    "    ################\n",
    "\n",
    "    # embedding -> [batch_size, sequence_length, embedding_dim]\n",
    "    ### YOUR CODE HERE ###\n",
    "    decoder_input_embed = emb_layer(decoder_input)\n",
    "\n",
    "    # dropout at embedding layer\n",
    "    ### YOUR CODE HERE ###\n",
    "    decoder_input_droped = Dropout(dropout_rate)(decoder_input_embed)\n",
    "\n",
    "    # add multiple Unidirectional GRU layers here,\n",
    "    # set units=2*hidden_dim, return_sequences=True\n",
    "    # set initial_state=encoder_hidden_state at the first layer\n",
    "    # please read https://keras.io/layers/recurrent/\n",
    "    # output:\n",
    "    # gru_output -> [batch_size, sequence_length, 2*hidden_dim]\n",
    "\n",
    "    # 1 layer of Unidirectional GRU, whose input is the output of the encoder’s last layer\n",
    "    # and initial hidden state is the encoder’s last state, i.e., initial_state=concatenate([encoder_last_h, encoder_last_hr], axis=1)\n",
    "    ### YOUR CODE HERE ###\n",
    "    initial_state = concatenate([encoder_last_h, encoder_last_hr], axis=1)\n",
    "    decoder_output = GRU(2*hidden_dim, return_sequences=True, unroll=True)(decoder_input_droped, initial_state)\n",
    "    decoder_outputs = [decoder_output]\n",
    "    # M − 1 layer(s) of Unidirectional GRU.\n",
    "    # Dropout layers between GRU layers if applicable (optional).\n",
    "    for i in range(1, num_decoder_layer):\n",
    "        ### YOUR CODE HERE ###\n",
    "        decoder_outputs = Dropout(dropout_rate)(decoder_outputs[i])\n",
    "        pass\n",
    "\n",
    "    # simple seq2seq without any attention mechanism\n",
    "    if attention_type is None:\n",
    "        # 1 layer of Dense layer with softmax activation wrapped by TimeDistributed.\n",
    "        output = TimeDistributed(\n",
    "            Dense(units=vocab_size, activation='softmax'))(decoder_outputs[-1])\n",
    "    else:\n",
    "        # dot-product attention\n",
    "        # weight_{i,j} = softmax(\\sum_k {decoder_output_{i,k} * encoder_output_{j,k}})\n",
    "        if attention_type == 'dot':\n",
    "            ### YOUR CODE HERE ###\n",
    "            weight = Activation('softmax')(\n",
    "                dot([decoder_outputs[-1], encoder_output], axes=[2, 2]))\n",
    "        # multiplicative attention\n",
    "        # weight_{i,j} = softmax(\\sum_k {decoder_output_{i,k} * (W encoder_output_{j,k})})\n",
    "        elif attention_type == 'multiplicative':\n",
    "            encoder_output_maped = Dense(units=2*hidden_dim, bias=False)(encoder_output)\n",
    "            weight = Activation('softmax')(\n",
    "                dot([decoder_outputs[-1], encoder_output_maped], axes=[2, 2]))\n",
    "        # additive attention\n",
    "        # weight_{i, j} = softmax(\\sum_k {V tanh(W1 decoder_output_{i,k} + W2 encoder_output_{j,k})})\n",
    "        elif attention_type == 'additive':\n",
    "            # You may need the help of the Lambda wrapper(https://keras.io/layers/core/#lambda)\n",
    "            # the K.expand_dims function and the K.squeeze function(https://keras.io/backend/#backend-functions\n",
    "            decoder_output_maped = Dense(units=2*hidden_dim, bias=False)(decoder_output)\n",
    "            encoder_output_maped = Dense(units=2*hidden_dim, bias=False)(encoder_output)\n",
    "            tanh_result = Activation('tanh')(Add()([\n",
    "                Lambda(lambda x: K.expand_dims(x, axis=2))(decoder_output_maped), \n",
    "                Lambda(lambda x: K.expand_dims(x, axis=1))(encoder_output_maped)]))\n",
    "            weight = Activation('softmax')(\n",
    "                Lambda(lambda x: K.squeeze(x, axis=3))(\n",
    "                    Dense(units=1, bias=False)(tanh_result)))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        attention = dot([weight, encoder_output], axes=[2, 1])\n",
    "        output = TimeDistributed(Dense(units=vocab_size, activation='softmax'))(\n",
    "            concatenate([decoder_outputs[-1], attention], axis=2))\n",
    "\n",
    "    model = Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
    "\n",
    "    adam = Adam()\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=adam)\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    print(\"Traning Model...\")\n",
    "    history = model.fit([encoder_input_train, decoder_input_train], np.expand_dims(decoder_target_train, axis=2), \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=epochs,\n",
    "                        verbose=1 if os.name == 'posix' else 2, \n",
    "                        callbacks=[TestCallback((encoder_input_valid, decoder_input_valid, decoder_target_valid), model, vocabulary)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
